\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english] {babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{graphics}
\usepackage{ulem}
\usepackage{amssymb}
\usepackage{url}
\usepackage{circuitikz}
\usepackage{subfig}
\usepackage[a4paper]{geometry}
\geometry{hscale=0.7,vscale=0.7,centering}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{moreverb}
\usepackage{listings}
\usepackage{qtree}
\graphicspath{{IMAGES/}}
\newtheorem{theorem}{Théorème}[section]
\newtheorem{defi}{Définition}[section]
\newtheorem{propri}{Propriété}[section]
\newtheorem{ex}{Exemple}[section]
\newtheorem{thesis}{Thèse}[section]
\newtheorem{cor}{Corollaire}[section]

\usepackage{color}

\definecolor{gris}{rgb}{0.95,0.95,0.95}


% Param�rage des listings
\lstset{basicstyle=\footnotesize\ttfamily}
\lstset{keywordstyle=\color[rgb]{0,0,1}\bfseries}
\lstset{identifierstyle=\color{black}}
\lstset{commentstyle=\color[rgb]{0,0.4,0}}
\lstset{stringstyle=\color[rgb]{0.7,0,0}}
\lstset{showstringspaces=false}
\lstset{showtabs=false}
\lstset{tabsize=3}
\lstset{extendedchars=true}
\lstset{breaklines=true}
\lstset{postbreak={}}
\lstset{breakautoindent=true}
\lstset{breakindent=0pt}
\lstset{xleftmargin=0.1cm}
\lstset{xrightmargin=0cm}
\lstset{frame=tb,rulecolor=\color[gray]{.4}}
\lstset{captionpos=b}
\lstset{aboveskip=0.5cm,belowskip=0.5cm}
\lstset{numbers=left}
\lstset{columns=fixed}



\newcommand{\code}[1]{\lstinline{#1}}

\setlength{\parskip}{.7em}

\begin{document}


\begin{flushleft}
\includegraphics[scale=0.3]{logo_ist.jpeg}
\end{flushleft}


\vspace{1cm}

\begin{center}{
\scshape{\LARGE Wolves and squirrel : Part 2 }}

\vspace{0.5cm}
\hbox{\raisebox{0.4em}{\vrule depth 0pt height 0.05cm width 16cm}}
{\setlength{\parskip}{0.2cm}

 \Huge
 \bfseries
 \LARGE  Parallel and Distributed Computing
 \\
CPD \\

\vspace{0.2cm}

}
\vspace{0.5cm}

\hbox{\raisebox{0.4em}{\vrule depth 0pt height 0.05cm width 16cm}}
\vspace{2.5cm}


\end{center}

\vspace{3cm}


\vfill
\begin{flushright}
\textbf{Group 30 :}\\
Cappart Quentin (77827)\\
Mikołaj Jakubowski (77610)\\
Paulo Tome (72419)\\

\end{flushright}
\newpage

\setcounter{page}{1}

\renewcommand\thepage{\arabic{page}}


\newpage

\section*{MPI Architecture}

Our program is based on a Master and Servant model.
In this model, we have two sorts of nodes, the master and the servants.
In few words, the master is the coordinator of the work, and the servants will deal only with a sub-board of the total board.
Let's describe all of this more concretely.

\paragraph{MPI Message}
~\\

We have severals type of messages between the master and the servants :

\begin{enumerate}
 \item \texttt{NEW\_BOARD(side:int)} : Message sent by the master to the servants to give them a part of the board.
 \item \texttt{UPDATE\_CELL(c : cell\_t)} : Message sent by the master or by the servants to notify a modification on particular cells.
 \item \texttt{FINISHED()} : Message sent by the master or by the servants to notify the finishing of a particular task.
 \item \texttt{START\_NEXT\_GENERATION(RED or BLACK)} : Message sent by the master to tell the servants to begin the computation
 of a new generation.
\end{enumerate}

\paragraph{Master}
~\\

There is only one master in the program. He's in charge of the coordination of all the work. He does the following actions :

\begin{lstlisting}
Load the world from the input file
Split the world in different parts (One per servant)
Send a sub-board to every servants.
Send FINISHED to confirm sending all cells

for i in 0 -> 2*Nb of generations:
    Send START_NEXT_GENERATION(color) to every node
    Listen for incoming updates and save them
    Count FINISHED messages
    if(count == Nb of slaves):
	break;
    Send stored updates to all servants
    Send FINISHED to all servants
    
Send FINISHED to all servants // all generations are finished
Listen for UPDATE_CELL and save them
Count FINISHED messages
if(count == Nb of slaves):
    Print output
    Exit
\end{lstlisting}


\paragraph{Servants}
~\\

All the other computers are servants of the master. Each of them receives a sub-board. The distribution of the work follow this idea.
Each servants do the following actions :

\begin{lstlisting}
 Listen for NEW_BOARD message
 Allocate memory for its board part
 Listen for FINISHED message // all cells are in place
 while true:
    Listen for message
    if(message = FINISHED):
	break;
    elif(message = START_NEXT_GENERATION(genInfo):
	Start a new generation
    Compute its part of the board
    Send UPDATE_CELL to the master the message with the modified cells
    Send FINISHED to the master
    Listen for UPDATE_CELL messages from master
    Update the cells and resolve conflicts
    Listen for FINISHED message from master
 Sends UPDATE_CELL to the master with all the cells.
 Exit
\end{lstlisting}



\section*{Ghost lines}

\section*{Performances analysis}


\section*{Decomposition done}

To understand our decomposition, we must explain before how our serial version works.
The main work are done in the huge worldLoop :

\begin{lstlisting}
for(i = 0 ; i < 4 * noOfGenerations ; i++){...}
\end{lstlisting}

What is particular is that we iterate to 4 times the number of generations. This structure was done to do the following things :

\begin{enumerate}
 \item We proceed the red generation and we keep all the conflicting movement.
 \item We deal with the conflicting movement of the red generation.
 \item We proceed the black generation and we keep all the conflicting movement.
 \item We deal with the conflicting movement of the black generation.
\end{enumerate}

Each part are done in one particular iteration, the correct action are chosen thanks to modulo and conditional operation.
With this structure we don't want to parallelize this main loop, but only his content. 
And after each iteration we need to synchronize. So, our parallelization are done like this 

\begin{lstlisting}
#pragma omp parallel for private(x,y,cell)
for(y = 0 ; y < worldSideLen ; y++){
      for(x = 0 ; x < worldSideLen ; x++){
	      //proceeding the cells
      }
)
\end{lstlisting}

Let's notice that we only parallelize on the row and not on the column because of the cache and to keep the adjacent portion of memory
together.

\section*{Conflict resolution}

The conflict resolution is done by the architecture of the serial version. Indeed, all the conflicting movement are not made
directly but their are kept in memory and proceeded after each subgeneration with the \texttt{update} method.
So, with the parallelization, given that we have an implicit synchronization after each iteration of the main loop (generation loop),
the conflict are implicitly resolved. We made sure after that our outputs with severals threads are always the same than the serial version.

\section*{Load Balancing}
Logic of every sub-generation is divied in two steps. 
Selecting updates and updating itself. 
Second phase is done per cell, so it is easy to parallelize. 
Every cell has a list of updates that needs to be invoked on it. 
Load balancing is done by diving those lists evenly between cores by dynamic sheduling. It's done by this pragma
in the \texttt{update} fonction :

\begin{lstlisting}
 #pragma omp parallel for schedule(dynamic,1)
\end{lstlisting}

We add it in the code, but it gave a slower execution time, so we didn't integrate it in our final version.

\section*{Performances analysis}

The following array recaps the execution time of the OMP version with severals numbers of threads.
\begin{table}[!ht]
\centering
\begin{tabular}{|r||r|r|r|r|}
  \hline
    Instance     & 1 thread   & 2 threads   & 4 threads  & 8 threads  \\
  \hline
    ex3.in       &  0.008     & 0.008        & 0.017       &  0.020 \\ 
  \hline
    world\_10.in &  0.011      &  0.006       & 0.021       & 0.035 \\ 
  \hline
   world\_100.in &  0.111      & 0.070        & 0.068      & 0.1278 \\ 
  \hline
  world\_1000.in &  12.885   & 7.712       & 6.534      &  6.522 \\ 
  \hline
\end{tabular}
\caption{Performances (in sec) for the different instances.}
\end{table}

We did these experiments on a computer with 4 cores with the input \texttt{instance 10 9 8 100}. We
let to the "iteration print" in the code\footnote{If we remove it, the execution time is to fast to do an useful analyze.}.
First, we notice that for the smallest instance, \texttt{ex3.in},
more threads we have, the program is slower. This was expected. Indeed, given that the instance are small, the overhead of the threads (creation, repartition and
synchronization for example), surpass the gain of multithreading.
For the instance \texttt{world\_10.in}, we notice it from 4 threads.
For the biggest instance, \texttt{world\_1000.in}, we see the speedup when we deal with severals threads. The speedup per core decreases with the number
of threads\footnote{We gain more from 1 to 2 threads than for 2 to 4 threads.}.
Finally, given that the computer has 4 cores, we are not interested in creating more than.
\\

Now, let's compare the execution time for  world\_1000.in with the ideal speedup\footnote{$S = \frac{T_{serial}}{N_{threads}}$}
with different numbers of threads :



With two threads we are relatively close to the ideal speedup. However the gap grows with more threads. We expected this king of results.
Indeed, there is always overhead when we deal with threads and not all of our code is multithreaded, so it's normal that we don't reach
the ideal result.
\end{document}

